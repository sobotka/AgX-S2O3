# What?

Given that I've neglected this repository for a while, and the expanse to which
the concepts inside of it have spread, I figured it was time for an introductory
explanation.

I have been asked about the experimental concept in AgX many, many, many times,
including from many different minds. These minds span rendering engineers,
colourists, educators, motion picture technicians, cinematographers, and many
others. This is not a testament to any "magic" within this general idea, but
rather a genuine inquisitive mindset that is an entry point to a very deep
rabbit hole.

The experiment is in fact based on top of a rather deeper set of concepts that
at some point I hope I'll be able to elucidate more clearly as best as I have
come to understand them. Consider this document to be a tip of a much, much,
much larger iceberg that will rattle even the most stalwart beliefs in "colour",
and more specifically, *pictorial depictions*.

I say *hope* because my journey to understanding visual cognition continues...

# What? What?

This is the Python code to generate what has become known as "AgX" in some
internet circles. This is a *Picture Formation* experiment, that eventually
spread outward. There are various implementations all over the web at this
point.

Some examples of implementations:
* [The Bevy Game Rendering Engine](https://bevyengine.org/examples/3d-rendering/tonemapping/)
* [Autodesk's VRED 3D Product Visualization Software](https://help.autodesk.com/view/VREDPRODUCTS/2025/ENU/?guid=rend-vred-2025)
* [Eary's AgX Variation in Blender](https://developer.blender.org/docs/release_notes/4.0/color_management/)
* [ThreeJS](https://github.com/mrdoob/three.js/issues/27362)
* [Juan Pablo Zambrano's DaVinci Resolve 2499 DCTL](https://github.com/JuanPabloZambrano/DCTL)
* [Avoyd's Voxel Rendering Engine](https://www.enkisoftware.com/t/6208018276417536)
* [Google's Filament Rendering Engine](https://github.com/google/filament/pull/7236)
* [A Plethora of ShaderToy Implementations](https://www.shadertoy.com/view/cd3XWr)
* [IOLITE](https://iolite-engine.com/blog_posts/minimal_agx_implementation)
* [An Unreal Implementation](https://gist.github.com/nxrighthere/eb208dae8b66dbe452af223f276e46cc)

# What? What? What?

The above list is a sprawl of riffs off of the underlying basic concepts. But
none of the examples necessarily inform us what the hell it *is*.

The AgX concept was an experimentation to form pictorial depictions from
relative wattages in some colourimetrically defined colour space. It was
an *experiment* to test a general idea of making a pictorial formation
mechanism that would never *break*.

# What Is A "Broken Picture"?

There is a longstanding erroneous inference that a "picture" is "idealized" when
the stimuli in front of a camera, either virtual or physical, is transmitted
to a suitable medium.

This erroneous inference stems back many decades. Judd, Plaza, and Balcom<sup>1</sup> erroneously
made this inference back in 1950, via a report on the status of colour television. Judd, in
addition to being a colour researcher, knew a thing or two about pictures as he was employed
by Kodak at this time. Why was this inference erroneous?

MacAdam, another Kodak researcher and famous colour researcher, explored the idea of
colour reproduction in his canonical paper from 1951<sup>2</sup>. The long and short of
that work was that MacAdam had the rather prescient observation that a colourimetric
"reproduction" of stimuli yields a very peculiar cognition. TL;DR: It makes for a
cognitively dissonant pictorial depiction.

# What Sort of Absurd Idea is "Pictorial Formation"?

A wise and unnamed PhD has poked and prodded me to *define* what *I* mean by
*Picture Formation*. I've chosen these two words rather carefully.

When I orginally set a label upon this concept, it was *Image Formation*. The
problem is that the term *Image* carried far too much baggage and was far
too open ended in the common vernacular.

**Image** from [Etymology Online](https://www.etymonline.com/search?q=image):
>c. 1200, "piece of statuary; artificial representation that looks like a person or thing," from Old French image "image, likeness; figure, drawing, portrait; reflection; statue," earlier imagene (11c.), from Latin imaginem (nominative imago) "copy, imitation, likeness; statue, picture," also "phantom, ghost, apparition," figuratively "idea, appearance," from stem of imitari "to copy, imitate" (from PIE root *aim- "to copy").

I settled on the term *Picture* as it draws an important connection to a
*physical manifestation* of a depiction.

**Picture** from [Etymology Online]()
> early 15c., pictur, pictoure, pittour, pectur, "the process or art of drawing or painting," a sense now obsolete; also "a visual or graphic representation of a person, scene, object, etc.," from Latin pictura "painting," from pictus, past participle of pingere "to make pictures, to paint, to embroider," (see paint (v.)).

Discussions around *pictures* became a tad slippery when referred to as *image*,
and the etymology hints at this. Where *image* could refer to a more slippery and
nebulous notion of some state, I wanted a more concrete reference to a physical
manifestation.

# So What is Picture Formation?
## **Picture Formation**
&emsp;The **creation** and **integration** of stimuli into
a stimui specification encoding, where:
1. The spatiotemporal articulation of the stimuli comprises the authorial
*intended cogntion* of fissioning and decomposition of forms and arrangements.
2. The spatiotemporal articulation of the stimuli is constructed and arranged with the
idealized goal of *a maximal probability* that the audience-reader shall decode
the spatiotemporal articulation of the stimuli to the originating authorial
*intended cognition*.

A reasonably formed spatiotemporal articulation of the stimuli reduces the low order
cognitive computations and processing, and increases the probability of correctly
inferred, and authorially intended, cognitive forms and their cognitive *ordering*
and *sequencing*.

# Why?

The origin of the idea of pinpointing a direct output of a *pictorial formation*,
using some metric of physics, became clearly a necessity for me during my study
at university. I was focusing on fine arts, and the specifics of chemical creative film.

The first big quesiton arose when I realized that the pictorial depiction of two
space opera characters had something that was cognitively dissonant. The
canonical lightsaber. Here, in a cultural trope, was a cognitive minefield.

![Darth vs Luke](/README_Assets/Darth_vs_Luke_-_Base.png "Darth vs Luke")

Specifically, it struck me that in no other case, beyond incredibly sustained
fixation, would any experience "lose colour". So why did this chemical creative
film mechanic work cognitively at all?

Decades later, I'd confirm something even more mind expanding. Having consumed far
too many research papers, I had a sneaking suspicion that what I had implicitly
assumed about those blasted lightsabers, might not be the case.

When we *read* the Darth vs Luke pictorial depiction, we believe we "see" colour.
In truth, it is a much more complex, elusive, and omnipresent calculation. For example,
try to make up what colour you think you "see" for Darth's lightsaber in this simple
pictorial depiction.

Ready?

Here's a sampling of stimuli, pulled out into an increment and decrement series of
stimuli swatches.

![Darth vs Luke](/README_Assets/Darth_vs_Luke_-_Stimuli_Red.png "Darth vs Luke")

Turns out the suspicion that the *colour* is nowhere in the stimuli. One can hunt
for hours trying to find a discrete sample of stimuli that in isolation can be
considered a satisfactory "match", only to be shocked that it is a futile endeavour.

The *colour* does not exist in the stimuli. The colour is a cognitive computation
that exists in our meatware.

# Back to Pictorial Formation

The question then turned to how to formulate pictures in a manner that would lead to
lower cognitive dissonance. I will not address the entire stack of reasoning here,
but it turns out that I had suspected a key hack would be to *offset* the wattage
present in the open domain colourimetry. In doing so, the way the samples would
ascend up the energy scale would *integrate* a basic offset toward the achromatic
global centroid. In doing so, it would specifically *avoid* the proliferation of
pictorial grammar errors that are omnipresent.

With a little tuning, it turns out that this approach worked reasonably well, and
lead to subsequent theory reading...

Hope this gives a very loose and broad strokes vantage on what specifically this
techniqe does, and why I have chosen some terminology that is different from the
conventional descriptions of "tone mapping".

----

<sup>1</sup>Judd DB, Plaza L, Balcom MM. The Present Status of Color Television; a report by the Senate Advisory Committee on Color Television. Smith N, Condon EU, Bailey SL, Everitt WL, Fink DG, eds. The Proceedings of the IRE. 1950;38(9):980-1002.
<sup>2</sup>MacAdam DL. Quality of Color Reproduction. Proc IRE. 1951;39(5):468-485. doi:10.1109/JRPROC.1951.232825

